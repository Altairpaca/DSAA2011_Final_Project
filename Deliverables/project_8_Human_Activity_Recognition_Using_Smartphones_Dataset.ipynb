{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e48b89a8",
   "metadata": {},
   "source": [
    "# Final Project - Group 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c96526c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, label_binarize\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import (accuracy_score, classification_report,\n",
    "                             confusion_matrix, ConfusionMatrixDisplay,\n",
    "                             roc_curve, auc, make_scorer, f1_score, precision_recall_fscore_support,\n",
    "                             silhouette_score, calinski_harabasz_score, davies_bouldin_score,\n",
    "                             adjusted_rand_score, normalized_mutual_info_score, homogeneity_score)\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from scipy.signal import welch\n",
    "from xgboost import XGBClassifier\n",
    "from typing import Literal\n",
    "\n",
    "import joblib\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e532b651",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb2a731",
   "metadata": {},
   "source": [
    "### Format the data into pandas.DataFrame\n",
    "After this preprocessing procedure, we can easily get the data as a DataFrame through pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b67b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(flag: Literal['train', 'test']) -> tuple[pd.DataFrame, pd.Series]:\n",
    "    \"\"\"\n",
    "    Load and process the UCI HAR Dataset for the specified data type ('train' or 'test').\n",
    "    :param flag: A string indicating the type of data to load ('train' or 'test').\n",
    "    :return: A pandas DataFrame containing the processed data with features and labels.\n",
    "    \"\"\"\n",
    "\n",
    "    # Read the data from the text files and create a DataFrame\n",
    "    return (pd.DataFrame((line.strip().split() for line in open(f'UCI HAR Dataset/{flag}/X_{flag}.txt', 'r')),\n",
    "                         columns=(feature.split()[1] for feature in open(\n",
    "                             'UCI HAR Dataset/features.txt', 'r')),\n",
    "                         dtype=np.float64),\n",
    "            pd.Series((label.strip() for label in open(\n",
    "                # Adjust labels to be zero-indexed\n",
    "                f'UCI HAR Dataset/{flag}/y_{flag}.txt')), name='label').astype(np.int8)-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec5f4bb",
   "metadata": {},
   "source": [
    "### Describe the data and check invalid values\n",
    "As we can see, there is no invalid values and all data has been normalized to $[-1,1]$.  \n",
    "So there is no need to do more normalization.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab48bdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch the data\n",
    "# X_train, y_train = get_data('train')\n",
    "# X_test, y_test = get_data('test')\n",
    "\n",
    "# Since the preprocessing has been done and the data is already available in CSV format,\n",
    "# we can directly load the data from CSV files to avoid reprocessing.\n",
    "X_train_df = pd.read_csv('data/X_train.csv')\n",
    "y_train_df = pd.read_csv('data/y_train.csv')\n",
    "X_test_df = pd.read_csv('data/X_test.csv')\n",
    "y_test_df = pd.read_csv('data/y_test.csv')\n",
    "\n",
    "# Convert the DataFrames to numpy arrays\n",
    "X_train = X_train_df.to_numpy()\n",
    "y_train = y_train_df.to_numpy().flatten()\n",
    "X_test = X_test_df.to_numpy()\n",
    "y_test = y_test_df.to_numpy().flatten()\n",
    "\n",
    "# Standardize to improve the model performance\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# # check the data again\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "print(X_train_df.isnull().sum().sum(), y_train_df.isnull().sum())\n",
    "print(X_test_df.isnull().sum().sum(), y_test_df.isnull().sum())\n",
    "print(np.isinf(X_train).sum().sum(), np.isinf(y_train).sum())\n",
    "print(np.isinf(X_test).sum().sum(), np.isinf(y_test).sum())\n",
    "\n",
    "print(X_train_df.describe())\n",
    "\n",
    "\n",
    "feature_columns = X_train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a992f2",
   "metadata": {},
   "source": [
    "### Save the data into csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4ab691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.to_csv('X_train.csv', index=False)\n",
    "# X_test.to_csv('X_test.csv', index=False)\n",
    "# y_train.to_csv('y_train.csv', index=False)\n",
    "# y_test.to_csv('y_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115b23d5",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24489f53",
   "metadata": {},
   "source": [
    "### Arrange the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344f1dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training dataset containing features\n",
    "df = pd.concat([X_train_df, X_test_df], axis=0, ignore_index=True)\n",
    "\n",
    "# Load the labels corresponding to the training dataset\n",
    "labels = pd.concat([y_train_df, y_test_df], axis=0,\n",
    "                   ignore_index=True).values.flatten()\n",
    "\n",
    "# Load the activity labels from the text file\n",
    "label_names = pd.read_csv('data/activity_labels.txt',\n",
    "                          header=None, names=['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f48e86",
   "metadata": {},
   "source": [
    "### Time-domain Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7014711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select specific time-domain features from the DataFrame\n",
    "time_features = df[['tBodyAcc-mean()-X', 'tBodyAcc-mean()-Y',\n",
    "                    'tBodyAcc-mean()-Z']]\n",
    "# Plot the time-domain features\n",
    "plt.figure(figsize=(12, 6))  # Set the figure size\n",
    "for i, col in enumerate(time_features.columns):\n",
    "    plt.subplot(3, 1, i+1)  # Create a subplot for each feature\n",
    "    plt.plot(time_features[col].values[:200])  # Plot the first 200 samples\n",
    "    plt.title(f'Time Domain: {col}')  # Set the title for each subplot\n",
    "    plt.ylabel('Amplitude')  # Label the y-axis\n",
    "plt.tight_layout()  # Adjust layout to prevent overlap\n",
    "plt.show()  # Display the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c52f35",
   "metadata": {},
   "source": [
    "### t-SNE Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddedc543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform t-SNE dimensionality reduction\n",
    "tsne = TSNE(\n",
    "    n_components=2,  # Reduce to 2 dimensions for visualization\n",
    "    perplexity=30,  # Controls the balance between local and global aspects\n",
    "    max_iter=300,  # Maximum number of iterations for optimization\n",
    "    learning_rate=200,  # Step size for optimization\n",
    "    random_state=42  # Ensure reproducibility\n",
    ")\n",
    "tsne_embeddings = tsne.fit_transform(df)\n",
    "\n",
    "# Visualize the t-SNE results\n",
    "plt.figure(figsize=(12, 8))  # Set the figure size\n",
    "scatter = plt.scatter(\n",
    "    tsne_embeddings[:, 0],  # First t-SNE component\n",
    "    tsne_embeddings[:, 1],  # Second t-SNE component\n",
    "    c=labels,  # Use activity labels for coloring\n",
    "    cmap=plt.get_cmap(\"viridis\", np.max(labels)+1),  # Colormap for labels\n",
    "    s=10,  # Marker size\n",
    "    alpha=0.7  # Transparency of markers\n",
    ")\n",
    "plt.colorbar(scatter, ticks=np.unique(labels),\n",
    "             label=\"Activity Label\")  # Add colorbar with labels\n",
    "plt.title(\"t-SNE Visualization of Sensor Data\")  # Set the plot title\n",
    "plt.xlabel(\"t-SNE Component 1\")  # Label for x-axis\n",
    "plt.ylabel(\"t-SNE Component 2\")  # Label for y-axis\n",
    "plt.show()  # Display the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad209777",
   "metadata": {},
   "source": [
    "### Frequency Domain Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5937a027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select specific frequency band energy features (example: 1-16Hz frequency band)\n",
    "freq_bands = df.filter(regex='bandsEnergy\\\\(\\\\)-1,16')\n",
    "\n",
    "# Create a logarithmic frequency range for the y-axis (1-16Hz, logarithmic scale)\n",
    "# Logarithmic distribution from 1Hz to 16Hz\n",
    "freq_range = np.logspace(0, np.log10(16), num=9)\n",
    "\n",
    "plt.figure(figsize=(12, 6))  # Set the figure size\n",
    "sns.heatmap(\n",
    "    freq_bands.iloc[:50].T,  # Transpose and display the first 50 samples\n",
    "    cmap=\"viridis\",  # Use the \"viridis\" colormap\n",
    "    cbar_kws={\"label\": \"Energy\"},  # Add a color bar with the label \"Energy\"\n",
    "    xticklabels=50,  # Set x-axis tick labels to show every 50th sample\n",
    "    # Round the frequency range to 1 decimal place for y-axis labels\n",
    "    yticklabels=freq_range.round(1)\n",
    ")\n",
    "# Set the plot title\n",
    "plt.title(\"Logarithmic Frequency Band Energy Distribution\")\n",
    "plt.xlabel(\"Sample Window\")  # Label for the x-axis\n",
    "plt.ylabel(\"Frequency (Hz)\")  # Label for the y-axis\n",
    "\n",
    "# Format the y-axis to display frequency values with one decimal place\n",
    "plt.gca().yaxis.set_major_formatter(\n",
    "    ticker.FuncFormatter(lambda x, pos: f\"{x:.1f}\")\n",
    ")\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addf4960",
   "metadata": {},
   "source": [
    "### Energy Distribution of Frequency Bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0922bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select energy features for the X, Y, and Z axes of body acceleration\n",
    "energy_features = df.loc[:, [\n",
    "    'tBodyAcc-energy()-X', 'tBodyAcc-energy()-Y', 'tBodyAcc-energy()-Z']]\n",
    "\n",
    "# Add the activity labels as a new column to the energy features DataFrame\n",
    "energy_features['label'] = label_names.loc[labels, 'name'].values\n",
    "\n",
    "# Create a boxplot to visualize the distribution of energy values for the X-axis\n",
    "# across different activity labels\n",
    "for ax in ['X', 'Y', 'Z']:\n",
    "    plt.figure(figsize=(10, 6))  # Set the figure size\n",
    "    sns.boxplot(x='label', y=f'tBodyAcc-energy()-{ax}',\n",
    "                data=energy_features)  # Create the boxplot\n",
    "    # Set the plot title\n",
    "    plt.title(f'Energy Distribution Across Activities ({ax})')\n",
    "    plt.xlabel('Activity Label')  # Label for the x-axis\n",
    "    plt.ylabel('Energy Value')  # Label for the y-axis\n",
    "    plt.show()  # Display the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe259020",
   "metadata": {},
   "source": [
    "### Inter-axis Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0257608d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select accelerometer inter-axis correlation features\n",
    "corr_features = df[['tBodyAcc-correlation()-X,Y',  # Correlation between X and Y axes\n",
    "                    'tBodyAcc-correlation()-X,Z',  # Correlation between X and Z axes\n",
    "                    'tBodyAcc-correlation()-Y,Z']]  # Correlation between Y and Z axes\n",
    "\n",
    "# Create a figure with specified size\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Generate a heatmap to visualize the correlation matrix\n",
    "sns.heatmap(\n",
    "    corr_features.corr(),  # Compute the correlation matrix of the selected features\n",
    "    annot=True,  # Display correlation values on the heatmap\n",
    "    cmap='coolwarm',  # Use the \"coolwarm\" colormap\n",
    "    vmin=-1, vmax=1,  # Set the range of correlation values\n",
    "    # Mask the upper triangle of the matrix\n",
    "    mask=np.triu(np.ones_like(corr_features.corr()))\n",
    ")\n",
    "\n",
    "# Add a title to the heatmap\n",
    "plt.title('Inter-axis Correlation Matrix')\n",
    "\n",
    "# Display the heatmap\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705dad5f",
   "metadata": {},
   "source": [
    "### Interquartile Range (IQR) and Entropy Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e2402e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a joint plot to visualize the relationship between two features:\n",
    "# 'tBodyAcc-iqr()-X' (Interquartile Range of Body Acceleration on X-axis)\n",
    "# and 'tBodyGyro-entropy()-Z' (Entropy of Body Gyroscope on Z-axis)\n",
    "sns.jointplot(\n",
    "    x='tBodyAcc-iqr()-X',  # Feature for the x-axis\n",
    "    y='tBodyGyro-entropy()-Z',  # Feature for the y-axis\n",
    "    data=df,  # Data source\n",
    "    kind='scatter',  # Type of plot: scatter plot\n",
    "    # Settings for marginal histograms\n",
    "    marginal_kws={'bins': 15, 'color': 'skyblue'},\n",
    "    height=8  # Size of the plot\n",
    ")\n",
    "\n",
    "# Add a title to the plot\n",
    "plt.suptitle('IQR vs Entropy Joint Distribution', y=1.02)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a78235f",
   "metadata": {},
   "source": [
    "### Power Spectral Density (PSD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5434c715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the Power Spectral Density (PSD) using Welch's method\n",
    "fs = 50  # Sampling rate in Hz\n",
    "# Compute PSD for the X-axis acceleration\n",
    "f, Pxx = welch(df[\"tBodyAcc-mean()-X\"], fs=fs, nperseg=128)\n",
    "\n",
    "# Create a figure with a specified size\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# Use GridSpec to create a layout with two rows and one column\n",
    "# The first row is 3 times taller than the second row\n",
    "gs = gridspec.GridSpec(2, 1, height_ratios=[3, 1])\n",
    "\n",
    "# Plot the time-domain signal\n",
    "ax1 = plt.subplot(gs[0])  # Create a subplot for the time-domain signal\n",
    "# Plot the first 200 samples of the signal\n",
    "ax1.plot(df[\"tBodyAcc-mean()-X\"][:200], label=\"Raw Signal\")\n",
    "# Set the title for the time-domain plot\n",
    "ax1.set_title(\"Time-Domain Signal with FFT Spectrum\")\n",
    "ax1.set_ylabel(\"Amplitude\")  # Label the y-axis\n",
    "ax1.legend()  # Add a legend to the plot\n",
    "\n",
    "# Plot the frequency-domain analysis (Power Spectral Density)\n",
    "ax2 = plt.subplot(gs[1])  # Create a subplot for the frequency-domain analysis\n",
    "# Plot the PSD on a logarithmic scale\n",
    "ax2.semilogy(f, Pxx[:len(f)], color=\"red\")\n",
    "ax2.set_xlim(0, 20)  # Limit the x-axis to frequencies between 0 and 20 Hz\n",
    "ax2.set_xlabel(\"Frequency (Hz)\")  # Label the x-axis\n",
    "ax2.set_ylabel(\"Power/Frequency (dB/Hz)\")  # Label the y-axis\n",
    "\n",
    "# Adjust the layout to prevent overlapping of subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db1b769",
   "metadata": {},
   "source": [
    "## Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5c7ff0",
   "metadata": {},
   "source": [
    "### Data Preprocessing and Algorithm Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9559d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train_scaled  # Feature dimensions: (10299, 561)\n",
    "y_true = y_train.flatten()\n",
    "\n",
    "# PCA Dimensionality Reduction (for faster computation and visualization)\n",
    "pca = PCA(n_components=0.95)  # Retain 95% variance\n",
    "X_pca = pca.fit_transform(X)\n",
    "print(f\"Dimensions after PCA: {X_pca.shape[1]}\")\n",
    "\n",
    "N = 18\n",
    "algorithms = {\n",
    "    \"K-Means\": KMeans(n_clusters=N, init='k-means++', random_state=42, algorithm='elkan'),\n",
    "    \"Hierarchical\": AgglomerativeClustering(n_clusters=N, linkage='ward'),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174b8439",
   "metadata": {},
   "source": [
    "### Evaluation Function (Internal + External Metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4cbe02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_clustering(X, labels, y_true=None):\n",
    "    metrics = {}\n",
    "\n",
    "    # Internal evaluation metrics\n",
    "    if len(np.unique(labels)) > 1:  # Exclude single-cluster cases\n",
    "        metrics['Silhouette'] = silhouette_score(X, labels)\n",
    "        metrics['Calinski-Harabasz'] = calinski_harabasz_score(X, labels)\n",
    "        metrics['Davies-Bouldin'] = davies_bouldin_score(X, labels)\n",
    "    else:\n",
    "        metrics.update(\n",
    "            {'Silhouette': np.nan, 'Calinski-Harabasz': np.nan, 'Davies-Bouldin': np.nan})\n",
    "\n",
    "    # External evaluation metrics (requires true labels)\n",
    "    if y_true is not None:\n",
    "        metrics['ARI'] = adjusted_rand_score(y_true, labels)\n",
    "        metrics['NMI'] = normalized_mutual_info_score(y_true, labels)\n",
    "        metrics['Homogeneity'] = homogeneity_score(y_true, labels)\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25be1ceb",
   "metadata": {},
   "source": [
    "### Perform Clustering and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7f05e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for name, model in algorithms.items():\n",
    "    # Train clustering model\n",
    "    cluster_labels = model.fit_predict(X_pca)\n",
    "\n",
    "    # Compute evaluation metrics\n",
    "    metrics = evaluate_clustering(X_pca, cluster_labels, y_true)\n",
    "    results[name] = metrics\n",
    "\n",
    "    # Print cluster distribution\n",
    "    unique, counts = np.unique(cluster_labels, return_counts=True)\n",
    "\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(\"\\n\\033[1m=== Clustering Performance Comparison ===\\033[0m\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2688cae6",
   "metadata": {},
   "source": [
    "### Visualization (PCA Reduced Space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a05a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 5))\n",
    "for i, (name, model) in enumerate(algorithms.items(), 1):\n",
    "    cluster_labels = model.fit_predict(X_pca)\n",
    "\n",
    "    # Plot predicted clusters\n",
    "    plt.subplot(1, 3, i)\n",
    "    scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=cluster_labels,\n",
    "                          cmap='viridis', s=10, alpha=0.6)\n",
    "    plt.title(f\"{name} Clustering (PCA)\")\n",
    "    plt.xlabel(\"Principal Component 1\")\n",
    "    plt.ylabel(\"Principal Component 2\")\n",
    "    plt.colorbar(scatter, ticks=np.unique(cluster_labels))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot True Labels for Comparison\n",
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y_true,\n",
    "                      cmap='viridis', s=10, alpha=0.6)\n",
    "plt.title(\"True Labels (PCA)\")\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.colorbar(scatter, ticks=np.unique(y_true))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9be305",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565081eb",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "##### Model Configuration Update & Enhanced Training Protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412e5cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CONFIG = {\n",
    "    'LogisticRegression': {\n",
    "        'class': LogisticRegression,\n",
    "        'params': {'max_iter': 1000, 'class_weight': 'balanced'}\n",
    "    },\n",
    "    'RandomForest': {\n",
    "        'class': RandomForestClassifier,\n",
    "        'params': {'n_estimators': 200, 'max_depth': 10, 'class_weight': 'balanced'}\n",
    "    },\n",
    "    'SVM': {\n",
    "        'class': SVC,\n",
    "        'params': {'kernel': 'rbf', 'C': 1.0, 'class_weight': 'balanced'}\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'class': XGBClassifier,\n",
    "        'params': {'eval_metric': 'logloss'}\n",
    "    },\n",
    "    'MLP': {\n",
    "        'class': MLPClassifier,\n",
    "        'params': {\n",
    "            'hidden_layer_sizes': (100, 50),  # Two hidden layers\n",
    "            'activation': 'relu',\n",
    "            'solver': 'adam',\n",
    "            'early_stopping': True,\n",
    "            'max_iter': 500,\n",
    "            'learning_rate_init': 0.001,\n",
    "            'batch_size': 256\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "def train_models(X_train, y_train):\n",
    "    trained_models = {}\n",
    "    for model_name, config in MODEL_CONFIG.items():\n",
    "        print(f\"\\nTraining {model_name}...\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        # model initialization\n",
    "        model = config['class'](**config['params'])\n",
    "\n",
    "        # Special handling for MLP convergence warnings\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "            model.fit(X_train, y_train)\n",
    "        # Track loss curve for neural networks\n",
    "        loss_curve = None\n",
    "        if hasattr(model, 'loss_curve_'):\n",
    "            loss_curve = model.loss_curve_\n",
    "\n",
    "        # record the model date\n",
    "        trained_models[model_name] = {\n",
    "            'model': model,\n",
    "            'train_time': time.time() - start_time,\n",
    "            'feature_importances': getattr(model, 'feature_importances_', None),\n",
    "            'loss_curve': loss_curve\n",
    "        }\n",
    "\n",
    "    return trained_models\n",
    "\n",
    "\n",
    "trained_models = train_models(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99c8a88",
   "metadata": {},
   "source": [
    "### Neural Network-Specific Analysis\n",
    "##### Add diagnostic visualizations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61953ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_neural_network_diagnostics(model_data):\n",
    "    if model_data['loss_curve'] is not None:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(model_data['loss_curve'])\n",
    "        plt.title('Training Loss Curve')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.show()\n",
    "\n",
    "    # Visualize layer weights\n",
    "    if isinstance(model_data['model'], MLPClassifier):\n",
    "        weights = model_data['model'].coefs_\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        for i, layer in enumerate(weights[:-1]):  # Exclude output layer\n",
    "            plt.subplot(1, len(weights)-1, i+1)\n",
    "            sns.heatmap(layer, cmap='viridis')\n",
    "            plt.title(f'Layer {i+1} Weights')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def predict_all_sets(model, X_train, X_test):\n",
    "    # Test the trained model on the training set, testing set and the entire set\n",
    "    X_full = np.vstack([X_train, X_test])\n",
    "    return {\n",
    "        'train': model.predict(X_train),\n",
    "        'test': model.predict(X_test),\n",
    "        'full': model.predict(X_full)\n",
    "    }\n",
    "\n",
    "\n",
    "def evaluate_model(y_true, y_pred, dataset_name, model_name):\n",
    "    # Generate metrics\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average='weighted', zero_division=0\n",
    "    )\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'confusion_matrix': confusion_matrix(y_true, y_pred),\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    ConfusionMatrixDisplay.from_predictions(y_true, y_pred)\n",
    "    plt.title(f'{model_name} - {dataset_name} Set Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def compare_models(results):\n",
    "    comparison = pd.DataFrame()\n",
    "    for model_name, data in results.items():\n",
    "        metrics = {\n",
    "            'Train Accuracy': data['train']['accuracy'],\n",
    "            'Test Accuracy': data['test']['accuracy'],\n",
    "            'Full Accuracy': data['full']['accuracy'],\n",
    "            'Train Precision': data['train']['precision'],\n",
    "            'Test Precision': data['test']['precision'],\n",
    "            'Full Precision': data['full']['precision'],\n",
    "            'Train Recall': data['train']['recall'],\n",
    "            'Test Recall': data['test']['recall'],\n",
    "            'Full Recall': data['full']['recall'],\n",
    "            'Train F1': data['train']['f1'],\n",
    "            'Test F1': data['test']['f1'],\n",
    "            'Full F1': data['full']['f1']\n",
    "        }\n",
    "        comparison[model_name] = pd.Series(metrics)\n",
    "    return comparison.T\n",
    "\n",
    "\n",
    "# Generate neural network diagnostics\n",
    "for name, data in trained_models.items():\n",
    "    if name == 'MLP':\n",
    "        plot_neural_network_diagnostics(data)\n",
    "\n",
    "# Prediction and evaluation flow\n",
    "results = {}\n",
    "for model_name, model_data in trained_models.items():\n",
    "    # Get predictions using scaled data\n",
    "    preds = predict_all_sets(\n",
    "        model_data['model'], X_train_scaled, X_test_scaled)\n",
    "\n",
    "    # Create full dataset labels\n",
    "    y_full = np.concatenate([y_train, y_test])\n",
    "\n",
    "    # Evaluate all sets with visualization\n",
    "    results[model_name] = {\n",
    "        'train': evaluate_model(y_train, preds['train'], 'Train', model_name),\n",
    "        'test': evaluate_model(y_test, preds['test'], 'Test', model_name),\n",
    "        'full': evaluate_model(y_full, preds['full'], 'Full', model_name)\n",
    "    }\n",
    "\n",
    "# Generate comparison table with full set metrics\n",
    "comparison_table = compare_models(results)\n",
    "print(\"\\nModel Performance Comparison:\")\n",
    "print(comparison_table)\n",
    "\n",
    "# ROC and AUC\n",
    "# Modify SVM configuration to enable probability estimates\n",
    "MODEL_CONFIG['SVM']['params']['probability'] = True\n",
    "\n",
    "# Function to plot ROC curves and compute AUC for each model\n",
    "\n",
    "\n",
    "def plot_roc_and_calculate_auc(trained_models, X_test_scaled, y_test):\n",
    "    for model_name, model_data in trained_models.items():\n",
    "        model = model_data['model']\n",
    "\n",
    "        # Skip models without probability estimates\n",
    "        if not hasattr(model, 'predict_proba'):\n",
    "            print(\n",
    "                f\"Skipping ROC/AUC for {model_name} (no probability support)\")\n",
    "            continue\n",
    "\n",
    "        # Get model's class information\n",
    "        model_classes = model.classes_\n",
    "        n_classes = len(model_classes)\n",
    "\n",
    "        # Binarize test labels according to model's classes\n",
    "        y_test_bin = label_binarize(y_test, classes=model_classes)\n",
    "\n",
    "        # Get predicted probabilities\n",
    "        y_prob = model.predict_proba(X_test_scaled)\n",
    "\n",
    "        # Initialize structures for ROC/AUC\n",
    "        fpr, tpr, roc_auc = {}, {}, {}\n",
    "\n",
    "        # Calculate metrics per class\n",
    "        for i in range(n_classes):\n",
    "            fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_prob[:, i])\n",
    "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "        # Compute macro-average\n",
    "        all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "        mean_tpr = np.zeros_like(all_fpr)\n",
    "        for i in range(n_classes):\n",
    "            mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "        mean_tpr /= n_classes\n",
    "        fpr[\"macro\"], tpr[\"macro\"] = all_fpr, mean_tpr\n",
    "        roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "        # Compute micro-average\n",
    "        fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(\n",
    "            y_test_bin.ravel(), y_prob.ravel())\n",
    "        roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "        # Visualization\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        colors = plt.cm.rainbow(np.linspace(0, 1, n_classes))\n",
    "\n",
    "        # Plot individual classes\n",
    "        for i, color in zip(range(n_classes), colors):\n",
    "            plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "                     label=f'Class {model_classes[i]} (AUC = {roc_auc[i]:.2f})')\n",
    "\n",
    "        # Plot averages\n",
    "        plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "                 label=f'Macro-average (AUC = {roc_auc[\"macro\"]:.2f})',\n",
    "                 color='navy', linestyle=':', linewidth=4)\n",
    "        plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "                 label=f'Micro-average (AUC = {roc_auc[\"micro\"]:.2f})',\n",
    "                 color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "        # Formatting\n",
    "        plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title(f'Multi-class ROC for {model_name}')\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Print metrics\n",
    "        print(f\"\\n{model_name} AUC Summary:\")\n",
    "        for i in range(n_classes):\n",
    "            print(f\"  Class {model_classes[i]}: {roc_auc[i]:.2f}\")\n",
    "        print(f\"  Macro-Average: {roc_auc['macro']:.2f}\")\n",
    "        print(f\"  Micro-Average: {roc_auc['micro']:.2f}\")\n",
    "\n",
    "\n",
    "# Execute ROC/AUC analysis\n",
    "plot_roc_and_calculate_auc(trained_models, X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbe43d8",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dc6548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Decision Boundaries using PCA\n",
    "\n",
    "\n",
    "def plot_decision_boundaries(trained_models, X_train, X_test, y_train):\n",
    "\n",
    "    # Combine train and test for full PCA fit\n",
    "    X_full = np.vstack([X_train, X_test])\n",
    "    pca = PCA(n_components=2)\n",
    "    pca.fit(X_full)\n",
    "\n",
    "    # Transform both train and test\n",
    "    X_train_pca = pca.transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "\n",
    "    # Create mesh grid\n",
    "    x_min, x_max = X_train_pca[:, 0].min() - 1, X_train_pca[:, 0].max() + 1\n",
    "    y_min, y_max = X_train_pca[:, 1].min() - 1, X_train_pca[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n",
    "                         np.arange(y_min, y_max, 0.02))\n",
    "\n",
    "    for model_name, model_data in trained_models.items():\n",
    "        model = model_data['model']\n",
    "        plt.figure(figsize=(10, 6))\n",
    "\n",
    "        # Predict on PCA meshgrid\n",
    "        Z = model.predict(pca.inverse_transform(np.c_[xx.ravel(), yy.ravel()]))\n",
    "        Z = Z.reshape(xx.shape)\n",
    "\n",
    "        # Plot decision boundary\n",
    "        plt.contourf(xx, yy, Z, alpha=0.8, cmap=plt.cm.RdYlBu)\n",
    "\n",
    "        # Plot training data points\n",
    "        scatter = plt.scatter(X_train_pca[:, 0], X_train_pca[:, 1], c=y_train,\n",
    "                              edgecolor='k', cmap=plt.cm.RdYlBu, s=50)\n",
    "        plt.xlabel('Principal Component 1')\n",
    "        plt.ylabel('Principal Component 2')\n",
    "        plt.title(f'Decision Boundary for {model_name}\\n(PCA Projection)')\n",
    "        plt.legend(*scatter.legend_elements(), title='Classes')\n",
    "        plt.show()\n",
    "\n",
    "# Visualize Feature Importances\n",
    "\n",
    "\n",
    "def plot_feature_importances(trained_models, feature_columns):\n",
    "    for model_name, model_data in trained_models.items():\n",
    "        importances = model_data['feature_importances']\n",
    "        if importances is not None:\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            indices = np.argsort(importances)[::-1][:10]  # Top 10 features\n",
    "            plt.title(f\"Feature Importances - {model_name}\")\n",
    "            plt.bar(range(len(indices)), importances[indices], align='center')\n",
    "            plt.xticks(range(len(indices)), [feature_columns[i] for i in indices],\n",
    "                       rotation=45, ha='right')\n",
    "            plt.xlim([-0.5, len(indices)-0.5])\n",
    "            plt.ylabel(\"Importance Score\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "# Execute visualization functions\n",
    "print(\"\\nGenerating Visualizations...\")\n",
    "plot_decision_boundaries(trained_models, X_train, X_test, y_train)\n",
    "plot_feature_importances(trained_models, feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0369e3",
   "metadata": {},
   "source": [
    "### Model Improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e02f6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CONFIG = {\n",
    "    'MLP': {\n",
    "        'class': MLPClassifier,\n",
    "        'params': {\n",
    "            'hidden_layer_sizes': (50,),  # Number of neurons in hidden layers\n",
    "            'activation': 'relu',  # Activation function\n",
    "            'solver': 'adam',  # Optimization algorithm\n",
    "            'alpha': 0.0001,  # Regularization term\n",
    "            'batch_size': 128,  # Batch size for training\n",
    "            'early_stopping': True,  # Stop training early if validation score doesn't improve\n",
    "            'max_iter': 500  # Maximum number of iterations\n",
    "        },\n",
    "        'grid_params': {  # Parameters for grid search optimization\n",
    "            # Different layer configurations\n",
    "            'hidden_layer_sizes': [(50,), (100, 50), (200, 100, 50)],\n",
    "            'activation': ['relu', 'tanh'],  # Activation functions to test\n",
    "            'alpha': [0.0001, 0.001, 0.01],  # Regularization strengths\n",
    "            'batch_size': [64, 128, 256],  # Batch sizes to test\n",
    "            'learning_rate_init': [0.001, 0.01],  # Initial learning rates\n",
    "            'early_stopping': [True]  # Whether to use early stopping\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# ================== Visualization Function ==================\n",
    "\n",
    "\n",
    "def plot_grid_search_results(model_data, model_name):\n",
    "    \"\"\"\n",
    "    Visualize the 3D parameter space of grid search results.\n",
    "    \"\"\"\n",
    "    results = model_data['grid_results']\n",
    "\n",
    "    # Convert grid search results to a DataFrame\n",
    "    df = pd.DataFrame(results.cv_results_)\n",
    "\n",
    "    # Select key parameters for visualization\n",
    "    viz_params = ['param_alpha', 'param_batch_size',\n",
    "                  'param_learning_rate_init']\n",
    "\n",
    "    plt.figure(figsize=(15, 10))\n",
    "\n",
    "    # 3D scatter plot for parameter combinations\n",
    "    ax = plt.subplot(221, projection='3d')\n",
    "    sc = ax.scatter3D(df[viz_params[0]], df[viz_params[1]], df[viz_params[2]],\n",
    "                      c=df['mean_test_score'], cmap='viridis', s=100)\n",
    "    ax.set_xlabel(viz_params[0].split('_')[-1])  # Label for x-axis\n",
    "    ax.set_ylabel(viz_params[1].split('_')[-1])  # Label for y-axis\n",
    "    ax.set_zlabel(viz_params[2].split('_')[-1])  # Label for z-axis\n",
    "    plt.colorbar(sc, label='Accuracy')  # Color bar for accuracy\n",
    "\n",
    "    # Heatmap for alpha vs batch_size\n",
    "    plt.subplot(223)\n",
    "    pivot_df = df.pivot_table(values='mean_test_score',\n",
    "                              index='param_alpha',\n",
    "                              columns='param_batch_size')\n",
    "    # Annotate heatmap with scores\n",
    "    sns.heatmap(pivot_df, annot=True, fmt=\".3f\")\n",
    "\n",
    "    # Scatter plot for training time vs accuracy\n",
    "    plt.subplot(224)\n",
    "    plt.scatter(df['mean_fit_time'], df['mean_test_score'], c=df['param_learning_rate_init'],\n",
    "                cmap='coolwarm')\n",
    "    plt.xlabel('Training Time (s)')  # Label for x-axis\n",
    "    plt.ylabel('Accuracy')  # Label for y-axis\n",
    "    plt.colorbar(label='Learning Rate')  # Color bar for learning rate\n",
    "\n",
    "    # Title for the entire plot\n",
    "    plt.suptitle(f'{model_name} Grid Search Analysis')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ================== Grid Search Optimization Function ==================\n",
    "\n",
    "\n",
    "def improve_models_via_gridsearch(trained_models, MODEL_CONFIG, X_train, y_train):\n",
    "    \"\"\"\n",
    "    Perform grid search optimization for models.\n",
    "    \"\"\"\n",
    "    improved_models = {}\n",
    "\n",
    "    for model_name, base_model in trained_models.items():\n",
    "        if model_name not in MODEL_CONFIG:\n",
    "            continue  # Skip models not in the configuration\n",
    "\n",
    "        print(f\"\\n=== Optimizing {model_name} ===\")\n",
    "        config = MODEL_CONFIG[model_name]\n",
    "\n",
    "        # Initialize grid search\n",
    "        grid = GridSearchCV(\n",
    "            estimator=base_model,\n",
    "            param_grid=config.get('grid_params', {}),\n",
    "            scoring='accuracy',  # Metric to optimize\n",
    "            cv=3,  # Number of cross-validation folds\n",
    "            n_jobs=-1,  # Use all available CPU cores\n",
    "            verbose=2  # Print progress during grid search\n",
    "        )\n",
    "\n",
    "        # Perform grid search\n",
    "        grid.fit(X_train, y_train)\n",
    "\n",
    "        # Save the best model and results\n",
    "        improved_models[model_name] = {\n",
    "            'best_model': grid.best_estimator_,  # Best model\n",
    "            'best_params': grid.best_params_,  # Best parameters\n",
    "            'best_score': grid.best_score_,  # Best accuracy score\n",
    "            'grid_results': grid  # Full grid search results\n",
    "        }\n",
    "\n",
    "        # Visualize grid search results\n",
    "        plot_grid_search_results(improved_models[model_name], model_name)\n",
    "\n",
    "    return improved_models\n",
    "\n",
    "\n",
    "# Initialize baseline models using the configuration\n",
    "base_models = {name: config['class'](**config['params'])\n",
    "               for name, config in MODEL_CONFIG.items()}\n",
    "\n",
    "# Optimize models using grid search\n",
    "improved_models = improve_models_via_gridsearch(\n",
    "    base_models,\n",
    "    MODEL_CONFIG,\n",
    "    X_train_scaled,  # Scaled training data\n",
    "    y_train  # Training labels\n",
    ")\n",
    "\n",
    "# Save the best models to disk\n",
    "for name, data in improved_models.items():\n",
    "    # Save model as a .pkl file\n",
    "    joblib.dump(data['best_model'], f'best_{name}.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
